{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc24570-12ca-4f00-a19d-d35fccec8fc8",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "#### Approach\n",
    "\n",
    "#### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099f91e-fae0-41c7-b6b6-c48297f413a4",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1a05b03e-5ebf-4624-b460-1e0e2ff85360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 3)) (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 5)) (4.3.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 7)) (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 8)) (3.8.7)\n",
      "Requirement already satisfied: textblob in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 9)) (0.19.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from -r requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->-r requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from gensim->-r requirements.txt (line 5)) (7.3.0.post1)\n",
      "Requirement already satisfied: colorama in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from nltk->-r requirements.txt (line 7)) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from nltk->-r requirements.txt (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from spacy->-r requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from spacy->-r requirements.txt (line 8)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (72.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from spacy->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 8)) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 8)) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 8)) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 8)) (2024.8.30)\n",
      "Requirement already satisfied: wrapt in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from smart-open>=1.8.1->gensim->-r requirements.txt (line 5)) (1.17.2)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 8)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 8)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 8)) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 8)) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zaid.qarout\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->spacy->-r requirements.txt (line 8)) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 8)) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 8)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\zaid.qarout\\appdata\\local\\miniconda3\\envs\\jupyter-env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 8)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "73cb2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 3.9/12.8 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.8/12.8 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.2/12.8 MB 13.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 9.9 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "     ---------------------------------------- 0.0/33.5 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 2.6/33.5 MB 16.9 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 6.3/33.5 MB 16.8 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 10.0/33.5 MB 17.3 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 13.4/33.5 MB 16.8 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 17.3/33.5 MB 17.0 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 21.0/33.5 MB 17.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 24.6/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 28.3/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 31.7/33.5 MB 16.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  33.3/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  33.3/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  33.3/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  33.3/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  33.3/33.5 MB 17.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 33.5/33.5 MB 10.6 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b519866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\Toxic Comment Classification Challenge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Zaid.Qarout\\Toxic Comment Classification Challenge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26038ec1-2b2a-4721-9fe7-ee3b365e1d45",
   "metadata": {},
   "source": [
    "## Importing Libraries and Defining Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6b9702af-ae70-4d31-9c93-e2fa27e7a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import scipy.sparse\n",
    "# import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from collections import Counter\n",
    "from spacy import displacy\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793dde5-44e5-408e-bde6-79f0808b537c",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0cf801b7-ca21-4e3d-a843-1fa16153ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data/train.csv'\n",
    "test_data_path = 'data/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b59354-5f03-4bff-9712-77dc6a12c35c",
   "metadata": {},
   "source": [
    "#### Observe the first 5 rows of each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fd53b169-5d0c-49ea-87cd-7b24ba077a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "22cc5d98-1162-4818-8387-aed02b4e39e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7fd70-b256-4028-8e14-e2f4ef81d641",
   "metadata": {},
   "source": [
    "#### Check the shape of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3cdd6173-c45a-4389-86dc-959e9b7ae4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (159571, 8)\n",
      "Test shape (153164, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape', df_train.shape)\n",
    "print('Test shape', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc306f8",
   "metadata": {},
   "source": [
    "#### Check the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c3a2f358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7519d29",
   "metadata": {},
   "source": [
    "#### Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f36bcb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4fe8a",
   "metadata": {},
   "source": [
    "#### View label distribution\n",
    "Sort values to see the most common labels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "aedb9f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "obscene           8449\n",
       "insult            7877\n",
       "severe_toxic      1595\n",
       "identity_hate     1405\n",
       "threat             478\n",
       "dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "df_train[labels].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2491e7b3",
   "metadata": {},
   "source": [
    "# 3. Preprocessing and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83b24d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "70933ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast, vector-ready model (has 300-d GloVe vectors)\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"ner\", \"parser\", \"tagger\"]) # Load the spaCy model with only the tokeniser\n",
    "\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579732c",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6e1fcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\"Function to clean the text data using spaCy.\n",
    "    Args:\n",
    "        doc (str): The text to be cleaned.\n",
    "    Returns: the cleaned text as a string.\"\"\"\n",
    "    PUNCTUATION_TABLE = str.maketrans(\"\", \"\", string.punctuation.replace(\"'\", \"\"))  # Remove punctuation except apostrophes\n",
    "    return text.lower().translate(PUNCTUATION_TABLE).replace('\\n', ' ').replace('\\r', ' ').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61135bc",
   "metadata": {},
   "source": [
    "### Tokenise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ee606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    \"\"\"Function to tokenise the text data using spaCy.\n",
    "    Args:\n",
    "        text (str): The text to be tokenised.\n",
    "    Returns: a list of tokens (lemmas) as strings.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    # Tokenise the document using spaCy\n",
    "    tokens = [\n",
    "        token.lemma.lower()\n",
    "        for token in doc\n",
    "        if (\n",
    "            not token.is_stop and  # Exclude stop words\n",
    "            not token.is_punct and  # Exclude punctuation\n",
    "            not token.is_space and  # Exclude spaces\n",
    "            len(token.text.strip()) > 1  # Exclude single-character tokens (e.g., 'a', 'I' etc. except for contractions like \"don't\", \"can't\" etc. which are handled by the tokenisation process)\n",
    "            not url_pattern.match(token.text) and # Exclude tokens that match the URL pattern\n",
    "            not email_pattern.match(token.text) and  # Exclude tokens that match the email pattern (e.g., '\n",
    "            not repetition_pattern.match(token.text) and # Exclude tokens that match the repetition pattern (e.g., 'aaaa', 'bbbb' etc.)\n",
    "            not emoji_pattern.match(token.text) and # Exclude tokens that match the emoji pattern (e.g., '😊', '😂' etc.)\n",
    "            not re.match(r'^\\d+$', token.text) and # Exclude tokens that are purely numeric (e.g., '123', '4567' etc. but keep numbers in words like \"one\", \"two\" etc. which are handled by the tokenisation process)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ee7eb",
   "metadata": {},
   "source": [
    "### Sentence count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "66ab2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_count(doc):\n",
    "    \"\"\" Function to count the number of sentences in the text data.\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): The processed text document.\n",
    "    Returns: the number of sentences.\"\"\"\n",
    "    return len(list(doc.sents))  # Count the number of sentences in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e50d83",
   "metadata": {},
   "source": [
    "### Get sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "02009cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores(text):\n",
    "    \"\"\"\n",
    "    Function to get the sentiment scores of the text data.\n",
    "    Args:\n",
    "        text (str): The text to be processed.\n",
    "    Returns: a dictionary with polarity and subjectivity scores.\"\"\"\n",
    "    blob = TextBlob(text)  # Create a TextBlob object\n",
    "    return {'polarity': blob.sentiment.polarity, 'subjectivity': blob.sentiment.subjectivity}  # Return the sentiment scores as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df343590",
   "metadata": {},
   "source": [
    "# 4. Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be8441",
   "metadata": {},
   "source": [
    "### Part-of-speech tagging (POS)\n",
    "Show the grammatical role of each word (eg. noun, verb...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a85e7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pos_tags(doc):\n",
    "    \"\"\" Function to print the part-of-speech (POS) tags of the text data.\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): The processed text document.\n",
    "    Returns: None, but prints the POS tags.\"\"\"\n",
    "    # Print each token and its POS tag\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} - {token.pos_}\")  # Print each token and its POS tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e9ab5",
   "metadata": {},
   "source": [
    "### Name entity recognition (NER)\n",
    "Finds named entities like countries, people, dates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1e7bee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ner(doc):\n",
    "    \"\"\" Function to print named entities in the text data.\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): The processed text document.\n",
    "    Returns: None, but prints the named entities.\"\"\"\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{ent.text} - {ent.label_}\")  # Print each entity and its label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e743fd",
   "metadata": {},
   "source": [
    "### Dependency parsing\n",
    "Shows how each word depends on another in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0f07163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dependency_parse(doc):\n",
    "    \"\"\" Function to print the dependency parse of the text data.\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): The processed text document.\n",
    "    Returns: None, but prints the dependency parse.\"\"\"\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} - {token.dep_} - {token.head.text}\")  # Print each token, its dependency relation, and its head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d49fba",
   "metadata": {},
   "source": [
    "### Sentiment counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fb36c",
   "metadata": {},
   "source": [
    "### Sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c805c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7bd0091",
   "metadata": {},
   "source": [
    "# 5. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9bf79bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    \"\"\" Function to extract features from the text data.\n",
    "    Args:\n",
    "        text (str): The text to be processed.\n",
    "    Returns: a dictionary with various features extracted from the text.\"\"\"\n",
    "    \n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        # Return default values if input is not valid\n",
    "        return {\n",
    "            'cleaned_text': '',\n",
    "            'tokens': [],\n",
    "            'sentence_count': 0,\n",
    "            'pos_tags': [],\n",
    "            'ner': [],\n",
    "            'dependency_parse': [],\n",
    "            'sentiment_scores': {'polarity': 0.0, 'subjectivity': 0.0}\n",
    "        }\n",
    "\n",
    "    \n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    return {\n",
    "        'cleaned_text': clean(text),  # Cleaned text\n",
    "        'tokens': tokenise(doc),  # Tokenised text\n",
    "        'sentence_count': sentence_count(doc),  # Number of sentences\n",
    "        'pos_tags': [(token.text, token.pos_) for token in doc],  # POS tags\n",
    "        'ner': [(ent.text, ent.label_) for ent in doc.ents],  # Named entities\n",
    "        'dependency_parse': [(token.text, token.dep_, token.head.text) for token in doc],  # Dependency parse\n",
    "        'sentiment_scores': get_sentiment_scores(text)  # Sentiment scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ca02b",
   "metadata": {},
   "source": [
    "### Apply data cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9cbdab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "# ============ DEVELOPMENT MODE =========== #\n",
    "# (a small sample to save time)\n",
    "\n",
    "df_small = df_train.sample(n=5000, random_state=42)\n",
    "features = df_small['comment_text'].apply(extract_features)\n",
    "features_df = pd.json_normalize(features, sep='_')\n",
    "\n",
    "df_small = df_small.reset_index(drop=True)\n",
    "features_df = features_df.reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([df_small, features_df], axis=1)\n",
    "# ========================================= #\n",
    "\n",
    "# ============ FULL DATASET MODE (SUBMISSION) =========== #\n",
    "# Uncomment this just before training and submission\n",
    "\n",
    "# features = df_train['comment_text'].apply(extract_features)\n",
    "# features_df = pd.json_normalize(features, sep='_')\n",
    "\n",
    "# Align indices before combining\n",
    "\n",
    "# df_train = df_train.reset_index(drop=True)\n",
    "# features_df = features_df.reset_index(drop=True)\n",
    "\n",
    "# Final working DataFrame for exploration\n",
    "\n",
    "# df = pd.concat([df_train, features_df], axis=1)\n",
    "# ======================================================== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "088111c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>ner</th>\n",
       "      <th>dependency_parse</th>\n",
       "      <th>sentiment_scores_polarity</th>\n",
       "      <th>sentiment_scores_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ca72b5b9c688e9e</td>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>geez are you forgetful  we've already discusse...</td>\n",
       "      <td>[geez, forgetful, discussed, marx, anarchist, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(Geez, ), (,, ), (are, ), (you, ), (forgetful...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Geez, , Geez), (,, , ,), (are, , are), (you,...</td>\n",
       "      <td>-8.333333e-03</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c03f72fd8f8bf54f</td>\n",
       "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>carioca rfa   thanks for your support on my re...</td>\n",
       "      <td>[carioca, rfa, thanks, support, request, admin...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(Carioca, ), (RFA, ), (\\n\\n, SPACE), (Thanks,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Carioca, , Carioca), (RFA, , RFA), (\\n\\n, , ...</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9e5b8e8fc1ff2e84</td>\n",
       "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday   no worries it's what i do enjoy ur ...</td>\n",
       "      <td>[birthday, worries, enjoy, ur, day|talk|e]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\", ), (\\n\\n , SPACE), (Birthday, ), (\\n\\n, S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(\", , \"), (\\n\\n , , \\n\\n ), (Birthday, , Birt...</td>\n",
       "      <td>3.250000e-01</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5332799e706665a6</td>\n",
       "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pseudoscience category   i'm assuming that thi...</td>\n",
       "      <td>[pseudoscience, category, assuming, article, p...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(Pseudoscience, ), (category, ), (?, ), (\\n\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Pseudoscience, , Pseudoscience), (category, ...</td>\n",
       "      <td>1.266667e-01</td>\n",
       "      <td>0.398333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfa7d8f0b4366680</td>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and if such phrase exists it would be provided...</td>\n",
       "      <td>[phrase, exists, provided, search, engine, men...</td>\n",
       "      <td>1</td>\n",
       "      <td>[((, ), (and, ), (if, ), (such, ), (phrase, ),...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((, , (), (and, , and), (if, , if), (such, , ...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>ba6f9b741648e4e4</td>\n",
       "      <td>\"\\n\\nIn response to Bduke's question 2 above, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in response to bduke's question 2 above i thin...</td>\n",
       "      <td>[response, bduke, question, 2, think, difficul...</td>\n",
       "      <td>9</td>\n",
       "      <td>[(\", ), (\\n\\n, SPACE), (In, ), (response, ), (...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(\", , \"), (\\n\\n, , \\n\\n), (In, , In), (respon...</td>\n",
       "      <td>-3.965082e-18</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>5c827588ebf39fe6</td>\n",
       "      <td>\"\\nSupport as above Slash \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support as above slash</td>\n",
       "      <td>[support, slash]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(\", ), (\\n, SPACE), (Support, ), (as, ), (abo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(\", , \"), (\\n, , \\n), (Support, , Support), (...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>e52f35b373fa6bbb</td>\n",
       "      <td>REDIRECT Talk:Magar class amphibious warfare v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talkmagar class amphibious warfare ve...</td>\n",
       "      <td>[redirect, talk, magar, class, amphibious, war...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(REDIRECT, ), (Talk, ), (:, ), (Magar, ), (cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(REDIRECT, , REDIRECT), (Talk, , Talk), (:, ,...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>7b681dbd3aa67ef6</td>\n",
       "      <td>\"\\n\\nSanger &amp; Sangists\\nI've added the \"\"\"\" te...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sanger  sangists i've added the  template to t...</td>\n",
       "      <td>[sanger, sangists, added, template, article, s...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(\", ), (\\n\\n, SPACE), (Sanger, ), (&amp;, ), (San...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(\", , \"), (\\n\\n, , \\n\\n), (Sanger, , Sanger),...</td>\n",
       "      <td>2.666667e-01</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>799315c85bf80509</td>\n",
       "      <td>Religious right will end up killing off all li...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>religious right will end up killing off all li...</td>\n",
       "      <td>[religious, right, end, killing, life, earth, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(Religious, ), (right, ), (will, ), (end, ), ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Religious, , Religious), (right, , right), (...</td>\n",
       "      <td>2.285714e-01</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "0     7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...   \n",
       "1     c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...   \n",
       "2     9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...   \n",
       "3     5332799e706665a6  Pseudoscience category? \\n\\nI'm assuming that ...   \n",
       "4     dfa7d8f0b4366680  (and if such phrase exists, it would be provid...   \n",
       "...                ...                                                ...   \n",
       "4995  ba6f9b741648e4e4  \"\\n\\nIn response to Bduke's question 2 above, ...   \n",
       "4996  5c827588ebf39fe6                        \"\\nSupport as above Slash \"   \n",
       "4997  e52f35b373fa6bbb  REDIRECT Talk:Magar class amphibious warfare v...   \n",
       "4998  7b681dbd3aa67ef6  \"\\n\\nSanger & Sangists\\nI've added the \"\"\"\" te...   \n",
       "4999  799315c85bf80509  Religious right will end up killing off all li...   \n",
       "\n",
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0         0             0        0       0       0              0   \n",
       "1         0             0        0       0       0              0   \n",
       "2         0             0        0       0       0              0   \n",
       "3         0             0        0       0       0              0   \n",
       "4         0             0        0       0       0              0   \n",
       "...     ...           ...      ...     ...     ...            ...   \n",
       "4995      0             0        0       0       0              0   \n",
       "4996      0             0        0       0       0              0   \n",
       "4997      0             0        0       0       0              0   \n",
       "4998      0             0        0       0       0              0   \n",
       "4999      1             0        0       0       0              0   \n",
       "\n",
       "                                           cleaned_text  \\\n",
       "0     geez are you forgetful  we've already discusse...   \n",
       "1     carioca rfa   thanks for your support on my re...   \n",
       "2     birthday   no worries it's what i do enjoy ur ...   \n",
       "3     pseudoscience category   i'm assuming that thi...   \n",
       "4     and if such phrase exists it would be provided...   \n",
       "...                                                 ...   \n",
       "4995  in response to bduke's question 2 above i thin...   \n",
       "4996                             support as above slash   \n",
       "4997  redirect talkmagar class amphibious warfare ve...   \n",
       "4998  sanger  sangists i've added the  template to t...   \n",
       "4999  religious right will end up killing off all li...   \n",
       "\n",
       "                                                 tokens  sentence_count  \\\n",
       "0     [geez, forgetful, discussed, marx, anarchist, ...               5   \n",
       "1     [carioca, rfa, thanks, support, request, admin...               4   \n",
       "2            [birthday, worries, enjoy, ur, day|talk|e]               1   \n",
       "3     [pseudoscience, category, assuming, article, p...               4   \n",
       "4     [phrase, exists, provided, search, engine, men...               1   \n",
       "...                                                 ...             ...   \n",
       "4995  [response, bduke, question, 2, think, difficul...               9   \n",
       "4996                                   [support, slash]               1   \n",
       "4997  [redirect, talk, magar, class, amphibious, war...               1   \n",
       "4998  [sanger, sangists, added, template, article, s...               5   \n",
       "4999  [religious, right, end, killing, life, earth, ...               1   \n",
       "\n",
       "                                               pos_tags ner  \\\n",
       "0     [(Geez, ), (,, ), (are, ), (you, ), (forgetful...  []   \n",
       "1     [(Carioca, ), (RFA, ), (\\n\\n, SPACE), (Thanks,...  []   \n",
       "2     [(\", ), (\\n\\n , SPACE), (Birthday, ), (\\n\\n, S...  []   \n",
       "3     [(Pseudoscience, ), (category, ), (?, ), (\\n\\n...  []   \n",
       "4     [((, ), (and, ), (if, ), (such, ), (phrase, ),...  []   \n",
       "...                                                 ...  ..   \n",
       "4995  [(\", ), (\\n\\n, SPACE), (In, ), (response, ), (...  []   \n",
       "4996  [(\", ), (\\n, SPACE), (Support, ), (as, ), (abo...  []   \n",
       "4997  [(REDIRECT, ), (Talk, ), (:, ), (Magar, ), (cl...  []   \n",
       "4998  [(\", ), (\\n\\n, SPACE), (Sanger, ), (&, ), (San...  []   \n",
       "4999  [(Religious, ), (right, ), (will, ), (end, ), ...  []   \n",
       "\n",
       "                                       dependency_parse  \\\n",
       "0     [(Geez, , Geez), (,, , ,), (are, , are), (you,...   \n",
       "1     [(Carioca, , Carioca), (RFA, , RFA), (\\n\\n, , ...   \n",
       "2     [(\", , \"), (\\n\\n , , \\n\\n ), (Birthday, , Birt...   \n",
       "3     [(Pseudoscience, , Pseudoscience), (category, ...   \n",
       "4     [((, , (), (and, , and), (if, , if), (such, , ...   \n",
       "...                                                 ...   \n",
       "4995  [(\", , \"), (\\n\\n, , \\n\\n), (In, , In), (respon...   \n",
       "4996  [(\", , \"), (\\n, , \\n), (Support, , Support), (...   \n",
       "4997  [(REDIRECT, , REDIRECT), (Talk, , Talk), (:, ,...   \n",
       "4998  [(\", , \"), (\\n\\n, , \\n\\n), (Sanger, , Sanger),...   \n",
       "4999  [(Religious, , Religious), (right, , right), (...   \n",
       "\n",
       "      sentiment_scores_polarity  sentiment_scores_subjectivity  \n",
       "0                 -8.333333e-03                       0.200000  \n",
       "1                  1.000000e-01                       0.600000  \n",
       "2                  3.250000e-01                       0.750000  \n",
       "3                  1.266667e-01                       0.398333  \n",
       "4                  0.000000e+00                       0.433333  \n",
       "...                         ...                            ...  \n",
       "4995              -3.965082e-18                       0.571429  \n",
       "4996               0.000000e+00                       0.100000  \n",
       "4997               0.000000e+00                       0.000000  \n",
       "4998               2.666667e-01                       0.550000  \n",
       "4999               2.285714e-01                       0.428571  \n",
       "\n",
       "[5000 rows x 16 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f4510",
   "metadata": {},
   "source": [
    "# 6. Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0f9eebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comments</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>15294</td>\n",
       "      <td>120035</td>\n",
       "      <td>396947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>1595</td>\n",
       "      <td>33133</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>8449</td>\n",
       "      <td>62418</td>\n",
       "      <td>217524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>478</td>\n",
       "      <td>10384</td>\n",
       "      <td>13010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>7877</td>\n",
       "      <td>59246</td>\n",
       "      <td>196900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>1405</td>\n",
       "      <td>8410</td>\n",
       "      <td>42551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  comments  sentences  tokens\n",
       "0          toxic     15294     120035  396947\n",
       "1   severe_toxic      1595      33133   73631\n",
       "2        obscene      8449      62418  217524\n",
       "3         threat       478      10384   13010\n",
       "4         insult      7877      59246  196900\n",
       "5  identity_hate      1405       8410   42551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_da242\">\n",
       "  <caption>Top-20 tokens per class</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_da242_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_da242_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_da242_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_da242_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_da242_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_da242_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_da242_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_da242_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_da242_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_da242_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_da242_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_da242_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_da242_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_da242_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_da242_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_da242_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_da242_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_da242_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "      <th id=\"T_da242_level0_col18\" class=\"col_heading level0 col18\" >18</th>\n",
       "      <th id=\"T_da242_level0_col19\" class=\"col_heading level0 col19\" >19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_da242_level0_row0\" class=\"row_heading level0 row0\" >toxic</th>\n",
       "      <td id=\"T_da242_row0_col0\" class=\"data row0 col0\" >fuck</td>\n",
       "      <td id=\"T_da242_row0_col1\" class=\"data row0 col1\" >=</td>\n",
       "      <td id=\"T_da242_row0_col2\" class=\"data row0 col2\" >shit</td>\n",
       "      <td id=\"T_da242_row0_col3\" class=\"data row0 col3\" >like</td>\n",
       "      <td id=\"T_da242_row0_col4\" class=\"data row0 col4\" >wikipedia</td>\n",
       "      <td id=\"T_da242_row0_col5\" class=\"data row0 col5\" >nigger</td>\n",
       "      <td id=\"T_da242_row0_col6\" class=\"data row0 col6\" >fucking</td>\n",
       "      <td id=\"T_da242_row0_col7\" class=\"data row0 col7\" >suck</td>\n",
       "      <td id=\"T_da242_row0_col8\" class=\"data row0 col8\" >ass</td>\n",
       "      <td id=\"T_da242_row0_col9\" class=\"data row0 col9\" >hate</td>\n",
       "      <td id=\"T_da242_row0_col10\" class=\"data row0 col10\" >u</td>\n",
       "      <td id=\"T_da242_row0_col11\" class=\"data row0 col11\" >gay</td>\n",
       "      <td id=\"T_da242_row0_col12\" class=\"data row0 col12\" >know</td>\n",
       "      <td id=\"T_da242_row0_col13\" class=\"data row0 col13\" >page</td>\n",
       "      <td id=\"T_da242_row0_col14\" class=\"data row0 col14\" >die</td>\n",
       "      <td id=\"T_da242_row0_col15\" class=\"data row0 col15\" >fat</td>\n",
       "      <td id=\"T_da242_row0_col16\" class=\"data row0 col16\" >faggot</td>\n",
       "      <td id=\"T_da242_row0_col17\" class=\"data row0 col17\" >people</td>\n",
       "      <td id=\"T_da242_row0_col18\" class=\"data row0 col18\" >moron</td>\n",
       "      <td id=\"T_da242_row0_col19\" class=\"data row0 col19\" >hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da242_level0_row1\" class=\"row_heading level0 row1\" >severe_toxic</th>\n",
       "      <td id=\"T_da242_row1_col0\" class=\"data row1 col0\" >fuck</td>\n",
       "      <td id=\"T_da242_row1_col1\" class=\"data row1 col1\" >suck</td>\n",
       "      <td id=\"T_da242_row1_col2\" class=\"data row1 col2\" >shit</td>\n",
       "      <td id=\"T_da242_row1_col3\" class=\"data row1 col3\" >ass</td>\n",
       "      <td id=\"T_da242_row1_col4\" class=\"data row1 col4\" >faggot</td>\n",
       "      <td id=\"T_da242_row1_col5\" class=\"data row1 col5\" >fucking</td>\n",
       "      <td id=\"T_da242_row1_col6\" class=\"data row1 col6\" >u</td>\n",
       "      <td id=\"T_da242_row1_col7\" class=\"data row1 col7\" >die</td>\n",
       "      <td id=\"T_da242_row1_col8\" class=\"data row1 col8\" >nigger</td>\n",
       "      <td id=\"T_da242_row1_col9\" class=\"data row1 col9\" >sucks</td>\n",
       "      <td id=\"T_da242_row1_col10\" class=\"data row1 col10\" >=</td>\n",
       "      <td id=\"T_da242_row1_col11\" class=\"data row1 col11\" >cunt</td>\n",
       "      <td id=\"T_da242_row1_col12\" class=\"data row1 col12\" >bitch</td>\n",
       "      <td id=\"T_da242_row1_col13\" class=\"data row1 col13\" >wikipedia</td>\n",
       "      <td id=\"T_da242_row1_col14\" class=\"data row1 col14\" >cock</td>\n",
       "      <td id=\"T_da242_row1_col15\" class=\"data row1 col15\" >fucksex</td>\n",
       "      <td id=\"T_da242_row1_col16\" class=\"data row1 col16\" >yourselfgo</td>\n",
       "      <td id=\"T_da242_row1_col17\" class=\"data row1 col17\" >fucker</td>\n",
       "      <td id=\"T_da242_row1_col18\" class=\"data row1 col18\" >kill</td>\n",
       "      <td id=\"T_da242_row1_col19\" class=\"data row1 col19\" >dick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da242_level0_row2\" class=\"row_heading level0 row2\" >obscene</th>\n",
       "      <td id=\"T_da242_row2_col0\" class=\"data row2 col0\" >fuck</td>\n",
       "      <td id=\"T_da242_row2_col1\" class=\"data row2 col1\" >shit</td>\n",
       "      <td id=\"T_da242_row2_col2\" class=\"data row2 col2\" >fucking</td>\n",
       "      <td id=\"T_da242_row2_col3\" class=\"data row2 col3\" >suck</td>\n",
       "      <td id=\"T_da242_row2_col4\" class=\"data row2 col4\" >nigger</td>\n",
       "      <td id=\"T_da242_row2_col5\" class=\"data row2 col5\" >ass</td>\n",
       "      <td id=\"T_da242_row2_col6\" class=\"data row2 col6\" >u</td>\n",
       "      <td id=\"T_da242_row2_col7\" class=\"data row2 col7\" >=</td>\n",
       "      <td id=\"T_da242_row2_col8\" class=\"data row2 col8\" >wikipedia</td>\n",
       "      <td id=\"T_da242_row2_col9\" class=\"data row2 col9\" >like</td>\n",
       "      <td id=\"T_da242_row2_col10\" class=\"data row2 col10\" >cunt</td>\n",
       "      <td id=\"T_da242_row2_col11\" class=\"data row2 col11\" >bitch</td>\n",
       "      <td id=\"T_da242_row2_col12\" class=\"data row2 col12\" >fat</td>\n",
       "      <td id=\"T_da242_row2_col13\" class=\"data row2 col13\" >know</td>\n",
       "      <td id=\"T_da242_row2_col14\" class=\"data row2 col14\" >die</td>\n",
       "      <td id=\"T_da242_row2_col15\" class=\"data row2 col15\" >dick</td>\n",
       "      <td id=\"T_da242_row2_col16\" class=\"data row2 col16\" >faggot</td>\n",
       "      <td id=\"T_da242_row2_col17\" class=\"data row2 col17\" >bullshit</td>\n",
       "      <td id=\"T_da242_row2_col18\" class=\"data row2 col18\" >page</td>\n",
       "      <td id=\"T_da242_row2_col19\" class=\"data row2 col19\" >sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da242_level0_row3\" class=\"row_heading level0 row3\" >threat</th>\n",
       "      <td id=\"T_da242_row3_col0\" class=\"data row3 col0\" >die</td>\n",
       "      <td id=\"T_da242_row3_col1\" class=\"data row3 col1\" >ass</td>\n",
       "      <td id=\"T_da242_row3_col2\" class=\"data row3 col2\" >kill</td>\n",
       "      <td id=\"T_da242_row3_col3\" class=\"data row3 col3\" >going</td>\n",
       "      <td id=\"T_da242_row3_col4\" class=\"data row3 col4\" >block</td>\n",
       "      <td id=\"T_da242_row3_col5\" class=\"data row3 col5\" >jim</td>\n",
       "      <td id=\"T_da242_row3_col6\" class=\"data row3 col6\" >wales</td>\n",
       "      <td id=\"T_da242_row3_col7\" class=\"data row3 col7\" >supertr0ll</td>\n",
       "      <td id=\"T_da242_row3_col8\" class=\"data row3 col8\" >fucking</td>\n",
       "      <td id=\"T_da242_row3_col9\" class=\"data row3 col9\" >fuck</td>\n",
       "      <td id=\"T_da242_row3_col10\" class=\"data row3 col10\" >ban</td>\n",
       "      <td id=\"T_da242_row3_col11\" class=\"data row3 col11\" >page</td>\n",
       "      <td id=\"T_da242_row3_col12\" class=\"data row3 col12\" >wikipedia</td>\n",
       "      <td id=\"T_da242_row3_col13\" class=\"data row3 col13\" >talk</td>\n",
       "      <td id=\"T_da242_row3_col14\" class=\"data row3 col14\" >murder</td>\n",
       "      <td id=\"T_da242_row3_col15\" class=\"data row3 col15\" >live</td>\n",
       "      <td id=\"T_da242_row3_col16\" class=\"data row3 col16\" >fuckin</td>\n",
       "      <td id=\"T_da242_row3_col17\" class=\"data row3 col17\" >rvv</td>\n",
       "      <td id=\"T_da242_row3_col18\" class=\"data row3 col18\" >blank</td>\n",
       "      <td id=\"T_da242_row3_col19\" class=\"data row3 col19\" >di</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da242_level0_row4\" class=\"row_heading level0 row4\" >insult</th>\n",
       "      <td id=\"T_da242_row4_col0\" class=\"data row4 col0\" >fuck</td>\n",
       "      <td id=\"T_da242_row4_col1\" class=\"data row4 col1\" >nigger</td>\n",
       "      <td id=\"T_da242_row4_col2\" class=\"data row4 col2\" >fucking</td>\n",
       "      <td id=\"T_da242_row4_col3\" class=\"data row4 col3\" >suck</td>\n",
       "      <td id=\"T_da242_row4_col4\" class=\"data row4 col4\" >u</td>\n",
       "      <td id=\"T_da242_row4_col5\" class=\"data row4 col5\" >ass</td>\n",
       "      <td id=\"T_da242_row4_col6\" class=\"data row4 col6\" >fat</td>\n",
       "      <td id=\"T_da242_row4_col7\" class=\"data row4 col7\" >faggot</td>\n",
       "      <td id=\"T_da242_row4_col8\" class=\"data row4 col8\" >=</td>\n",
       "      <td id=\"T_da242_row4_col9\" class=\"data row4 col9\" >shit</td>\n",
       "      <td id=\"T_da242_row4_col10\" class=\"data row4 col10\" >like</td>\n",
       "      <td id=\"T_da242_row4_col11\" class=\"data row4 col11\" >moron</td>\n",
       "      <td id=\"T_da242_row4_col12\" class=\"data row4 col12\" >cunt</td>\n",
       "      <td id=\"T_da242_row4_col13\" class=\"data row4 col13\" >hi</td>\n",
       "      <td id=\"T_da242_row4_col14\" class=\"data row4 col14\" >hate</td>\n",
       "      <td id=\"T_da242_row4_col15\" class=\"data row4 col15\" >bitch</td>\n",
       "      <td id=\"T_da242_row4_col16\" class=\"data row4 col16\" >jew</td>\n",
       "      <td id=\"T_da242_row4_col17\" class=\"data row4 col17\" >wikipedia</td>\n",
       "      <td id=\"T_da242_row4_col18\" class=\"data row4 col18\" >die</td>\n",
       "      <td id=\"T_da242_row4_col19\" class=\"data row4 col19\" >know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da242_level0_row5\" class=\"row_heading level0 row5\" >identity_hate</th>\n",
       "      <td id=\"T_da242_row5_col0\" class=\"data row5 col0\" >nigger</td>\n",
       "      <td id=\"T_da242_row5_col1\" class=\"data row5 col1\" >fat</td>\n",
       "      <td id=\"T_da242_row5_col2\" class=\"data row5 col2\" >jew</td>\n",
       "      <td id=\"T_da242_row5_col3\" class=\"data row5 col3\" >gay</td>\n",
       "      <td id=\"T_da242_row5_col4\" class=\"data row5 col4\" >die</td>\n",
       "      <td id=\"T_da242_row5_col5\" class=\"data row5 col5\" >fuck</td>\n",
       "      <td id=\"T_da242_row5_col6\" class=\"data row5 col6\" >faggot</td>\n",
       "      <td id=\"T_da242_row5_col7\" class=\"data row5 col7\" >fucking</td>\n",
       "      <td id=\"T_da242_row5_col8\" class=\"data row5 col8\" >huge</td>\n",
       "      <td id=\"T_da242_row5_col9\" class=\"data row5 col9\" >suck</td>\n",
       "      <td id=\"T_da242_row5_col10\" class=\"data row5 col10\" >shit</td>\n",
       "      <td id=\"T_da242_row5_col11\" class=\"data row5 col11\" >stupid</td>\n",
       "      <td id=\"T_da242_row5_col12\" class=\"data row5 col12\" >cunt</td>\n",
       "      <td id=\"T_da242_row5_col13\" class=\"data row5 col13\" >like</td>\n",
       "      <td id=\"T_da242_row5_col14\" class=\"data row5 col14\" >ass</td>\n",
       "      <td id=\"T_da242_row5_col15\" class=\"data row5 col15\" >mexicans</td>\n",
       "      <td id=\"T_da242_row5_col16\" class=\"data row5 col16\" >bitch</td>\n",
       "      <td id=\"T_da242_row5_col17\" class=\"data row5 col17\" >niggas</td>\n",
       "      <td id=\"T_da242_row5_col18\" class=\"data row5 col18\" >hate</td>\n",
       "      <td id=\"T_da242_row5_col19\" class=\"data row5 col19\" >bunksteve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1885e3393d0>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_rows, top_words = [], {}\n",
    "for lab in labels:\n",
    "    sub = df_train[df_train[lab]==1]\n",
    "    n_comments = len(sub)\n",
    "    n_sentences = sub[\"comment_text\"].str.count(r\"[.!?]\").sum()\n",
    "    all_tokens = np.concatenate(sub[\"comment_text\"].apply(tokenise).values)\n",
    "    n_tokens = len(all_tokens)\n",
    "    top_words[lab] = [w for w,_ in Counter(all_tokens).most_common(20)]\n",
    "    eda_rows.append((lab, n_comments, n_sentences, n_tokens))\n",
    "\n",
    "eda_df = pd.DataFrame(eda_rows, columns=[\"label\",\"comments\",\"sentences\",\"tokens\"])\n",
    "display(eda_df)\n",
    "pd.DataFrame(top_words).T.style.set_caption(\"Top-20 tokens per class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73f588",
   "metadata": {},
   "source": [
    "# 7. Text vectorisation (TF-IDF and WordEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0048271",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "38358c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is input features and y is the output labels\n",
    "\n",
    "df = df.dropna(subset=['cleaned_text'])\n",
    "X = df['cleaned_text']  # Features: cleaned text\n",
    "y = df[labels]  # Target labels\n",
    "\n",
    "X_train_tfidf, X_val_tfidf, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, random_state=42\n",
    ")  # Split the data into training and validation sets\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(\n",
    "    tokenizer=tokenise, # Tokeniser function to convert text to tokens\n",
    "    preprocessor=clean,  # Preprocessor function to clean the text\n",
    "    lowercase=False, # Skip internal lower-casing\n",
    "    min_df=2, # Minimum document frequency to ignore rare words\n",
    "    max_features=30_000, # Maximum number of features to consider\n",
    "    ngram_range=(1,2) # Vectoriser to convert text to TF-IDF features\n",
    ")  # Vectoriser to convert text to TF-IDF features\n",
    "# Note: tokenizer is a function that takes a string and returns a list of tokens\n",
    "\n",
    "X_tfidf_train = tfidf_vec.fit_transform(X_train_tfidf)\n",
    "X_tfidf_val  = tfidf_vec.transform(X_val_tfidf)\n",
    "\n",
    "# Save the TF-IDF matrices and vectoriser for later use\n",
    "scipy.sparse.save_npz(\"X_tfidf_train.npz\", X_tfidf_train) # Save the training TF-IDF matrix\n",
    "scipy.sparse.save_npz(\"X_tfidf_val.npz\", X_tfidf_val) # Save the validation TF-IDF matrix\n",
    "joblib.dump(tfidf_vec, \"tfidf_vectorizer.pkl\") # Save the TF-IDF vectoriser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c4b58",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "X_text_embed = df_train['comment_text'].apply(lambda x: nlp(x).vector) # Convert the text to word embeddings using spaCy\n",
    "# Note: This will create a 300-dimensional dense vector for each comment\n",
    "y_embed = df_train[labels] # Extract the labels for word embeddings\n",
    "\n",
    "X_train_embed, X_val_embed, y_train_embed, y_val_embed = train_test_split(\n",
    "    X_text_embed, y_embed, test_size=0.2, random_state=42\n",
    ") # Split the data into training and validation sets\n",
    "\n",
    "# Function to convert text to a dense vector using spaCy\n",
    "def doc_vector(text):\n",
    "    doc = nlp(text)\n",
    "    return doc.vector # 300-d dense vector\n",
    "\n",
    "X_embed_train = np.vstack(X_train_embed.values) # Convert the training text embeddings to a 2D array\n",
    "X_embed_val = np.vstack(X_val_embed.values) # Convert the validation text embeddings to a 2D array\n",
    "\n",
    "# Save the word embeddings for later use\n",
    "np.save(\"X_embed_train.npy\", X_embed_train)\n",
    "np.save(\"X_embed_val.npy\", X_embed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a378b0",
   "metadata": {},
   "source": [
    "# 8. Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGOS = {\n",
    "#     \"LogReg\" : LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "#     \"LinearSVM\": LinearSVC(class_weight=\"balanced\"),\n",
    "#     \"MultNB\" : MultinomialNB()\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf0712",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd34a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 TF-IDF + Logistic Regression\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.67      0.66      0.66        91\n",
      " severe_toxic       0.07      0.17      0.10         6\n",
      "      obscene       0.85      0.66      0.74        53\n",
      "       threat       0.00      0.00      0.00         3\n",
      "       insult       0.66      0.70      0.68        44\n",
      "identity_hate       0.29      0.33      0.31        12\n",
      "\n",
      "    micro avg       0.63      0.63      0.63       209\n",
      "    macro avg       0.42      0.42      0.42       209\n",
      " weighted avg       0.66      0.63      0.64       209\n",
      "  samples avg       0.05      0.05      0.05       209\n",
      "\n",
      "📘 Word Embedding + Logistic Regression\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.44      0.82      0.57      3056\n",
      " severe_toxic       0.14      0.90      0.24       321\n",
      "      obscene       0.38      0.84      0.52      1715\n",
      "       threat       0.03      0.89      0.06        74\n",
      "       insult       0.36      0.86      0.50      1614\n",
      "identity_hate       0.09      0.83      0.16       294\n",
      "\n",
      "    micro avg       0.29      0.84      0.44      7074\n",
      "    macro avg       0.24      0.86      0.34      7074\n",
      " weighted avg       0.37      0.84      0.51      7074\n",
      "  samples avg       0.05      0.08      0.06      7074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For TF-IDF\n",
    "model_tfidf = OneVsRestClassifier(LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "model_tfidf.fit(Xtr, y_train)\n",
    "y_pred_tfidf = model_tfidf.predict(Xv)\n",
    "\n",
    "print(\"TF-IDF + Logistic Regression\")\n",
    "print(classification_report(y_val, y_pred_tfidf, target_names=labels, zero_division=0))\n",
    "\n",
    "# For Word Embeddings\n",
    "model_embed = OneVsRestClassifier(LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "model_embed.fit(X_embed_train, y_train_embed)\n",
    "y_pred_embed = model_embed.predict(X_embed_val)\n",
    "\n",
    "print(\"Word Embedding + Logistic Regression\")\n",
    "print(classification_report(y_val_embed, y_pred_embed, target_names=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934ca61",
   "metadata": {},
   "source": [
    "## Multi-LayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fbbb3b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + MLP\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.79      0.53      0.63        91\n",
      " severe_toxic       0.00      0.00      0.00         6\n",
      "      obscene       0.77      0.43      0.55        53\n",
      "       threat       0.00      0.00      0.00         3\n",
      "       insult       0.65      0.45      0.53        44\n",
      "identity_hate       0.00      0.00      0.00        12\n",
      "\n",
      "    micro avg       0.69      0.44      0.54       209\n",
      "    macro avg       0.37      0.24      0.29       209\n",
      " weighted avg       0.67      0.44      0.53       209\n",
      "  samples avg       0.05      0.04      0.04       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zaid.Qarout\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding + MLP\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.71      0.57      0.63      3056\n",
      " severe_toxic       0.36      0.35      0.35       321\n",
      "      obscene       0.66      0.61      0.63      1715\n",
      "       threat       0.46      0.30      0.36        74\n",
      "       insult       0.65      0.54      0.59      1614\n",
      "identity_hate       0.39      0.31      0.34       294\n",
      "\n",
      "    micro avg       0.65      0.55      0.59      7074\n",
      "    macro avg       0.54      0.44      0.48      7074\n",
      " weighted avg       0.65      0.55      0.59      7074\n",
      "  samples avg       0.05      0.05      0.05      7074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For TF-IDF\n",
    "model_mlp_tfidf = OneVsRestClassifier(\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    ")\n",
    "model_mlp_tfidf.fit(X_tfidf_train, y_train)\n",
    "y_pred_mlp_tfidf = model_mlp_tfidf.predict(X_tfidf_val)\n",
    "\n",
    "print(\"TF-IDF + MLP\")\n",
    "print(classification_report(y_val, y_pred_mlp_tfidf, target_names=labels, zero_division=0))\n",
    "\n",
    "# For Word Embeddings\n",
    "model_mlp_embed = OneVsRestClassifier(\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    ")\n",
    "model_mlp_embed.fit(X_embed_train, y_train_embed)\n",
    "y_pred_mlp_embed = model_mlp_embed.predict(X_embed_val)\n",
    "\n",
    "print(\"Word Embedding + MLP\")\n",
    "print(classification_report(y_val_embed, y_pred_mlp_embed, target_names=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34deb6f",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "91e5985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + KNN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.74      0.49      0.59        91\n",
      " severe_toxic       0.00      0.00      0.00         6\n",
      "      obscene       0.87      0.49      0.63        53\n",
      "       threat       0.00      0.00      0.00         3\n",
      "       insult       0.69      0.41      0.51        44\n",
      "identity_hate       0.00      0.00      0.00        12\n",
      "\n",
      "    micro avg       0.72      0.43      0.54       209\n",
      "    macro avg       0.38      0.23      0.29       209\n",
      " weighted avg       0.69      0.43      0.52       209\n",
      "  samples avg       0.04      0.03      0.04       209\n",
      "\n",
      "Word Embedding + KNN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.67      0.48      0.56      3056\n",
      " severe_toxic       0.39      0.26      0.31       321\n",
      "      obscene       0.67      0.49      0.57      1715\n",
      "       threat       0.45      0.12      0.19        74\n",
      "       insult       0.62      0.44      0.52      1614\n",
      "identity_hate       0.40      0.12      0.19       294\n",
      "\n",
      "    micro avg       0.64      0.44      0.52      7074\n",
      "    macro avg       0.53      0.32      0.39      7074\n",
      " weighted avg       0.63      0.44      0.52      7074\n",
      "  samples avg       0.04      0.04      0.04      7074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For TF-IDF\n",
    "model_knn_tfidf = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=5, metric='cosine'))\n",
    "model_knn_tfidf.fit(X_tfidf_train, y_train)\n",
    "y_pred_knn_tfidf = model_knn_tfidf.predict(X_tfidf_val)\n",
    "\n",
    "print(\"TF-IDF + KNN\")\n",
    "print(classification_report(y_val, y_pred_knn_tfidf, target_names=labels, zero_division=0))\n",
    "\n",
    "# For Word Embeddings\n",
    "model_knn_embed = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=5, metric='cosine'))\n",
    "model_knn_embed.fit(X_embed_train, y_train_embed)\n",
    "y_pred_knn_embed = model_knn_embed.predict(X_embed_val)\n",
    "\n",
    "print(\"Word Embedding + KNN\")\n",
    "print(classification_report(y_val_embed, y_pred_knn_embed, target_names=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb068e21",
   "metadata": {},
   "source": [
    "# 9. Results visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0e1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_auc(y_true, y_scores, model_name, labels):\n",
    "    \"\"\" Function to evaluate AUC scores for each class and print the results.\n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels in a binary format (shape: [n_samples, n_classes]).\n",
    "        y_scores (np.ndarray): Predicted scores or probabilities (shape: [n_samples, n_classes]).\n",
    "        model_name (str): Name of the model being evaluated.\n",
    "        labels (list): List of class labels.\n",
    "    Returns:\n",
    "        auc_per_class (dict): A dictionary with AUC scores for each class.\n",
    "        macro_auc (float): Macro-average AUC score.\n",
    "        micro_auc (float): Micro-average AUC score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute AUC per class\n",
    "    auc_per_class = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "        except ValueError:\n",
    "            auc = 0.0  # If only one class present in y_true\n",
    "        auc_per_class[label] = auc\n",
    "\n",
    "    # Print AUC scores\n",
    "    print(f\"AUC Scores for: {model_name}\")\n",
    "    for label, auc in auc_per_class.items():\n",
    "        print(f\"  {label:<15}: {auc:.3f}\")\n",
    "\n",
    "    # Compute and print macro and micro averages\n",
    "    macro_auc = roc_auc_score(y_true, y_scores, average='macro')\n",
    "    micro_auc = roc_auc_score(y_true, y_scores, average='micro')\n",
    "\n",
    "    print(f\"\\nMacro AUC: {macro_auc:.3f}\")\n",
    "    print(f\"Micro AUC: {micro_auc:.3f}\")\n",
    "    \n",
    "    return auc_per_class, macro_auc, micro_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9752110",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure you have probability outputs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_scores_tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_tfidf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(X_tfidf_val)\n\u001b[0;32m      3\u001b[0m y_val_array \u001b[38;5;241m=\u001b[39m y_val\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Convert to NumPy array if it's a DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure you have probability outputs\n",
    "y_scores_tfidf = model_tfidf.predict_proba(X_tfidf_val)\n",
    "y_val_array = y_val.values  # Convert to NumPy array if it's a DataFrame\n",
    "\n",
    "# Evaluate\n",
    "evaluate_auc(y_val_array, y_scores_tfidf, \"TF-IDF + Logistic Regression\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f5cfa4b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[284], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_embed \u001b[38;5;241m=\u001b[39m OneVsRestClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel_embed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_embed_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_pred_embed \u001b[38;5;241m=\u001b[39m model_embed\u001b[38;5;241m.\u001b[39mpredict(X_embed_val)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m ):\n\u001b[1;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\multiclass.py:376\u001b[0m, in \u001b[0;36mOneVsRestClassifier.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    372\u001b[0m columns \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnot \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\multiclass.py:96\u001b[0m, in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, fit_params, classes)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m clone(estimator)\n\u001b[1;32m---> 96\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m ):\n\u001b[1;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1376\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1376\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1401\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:456\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    452\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    453\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    454\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    455\u001b[0m ]\n\u001b[1;32m--> 456\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    471\u001b[0m     solver,\n\u001b[0;32m    472\u001b[0m     opt_res,\n\u001b[0;32m    473\u001b[0m     max_iter,\n\u001b[0;32m    474\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    475\u001b[0m )\n\u001b[0;32m    476\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:316\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 316\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m sw_sum \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(sample_weight)\n\u001b[0;32m    323\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\jupyter-env\\Lib\\site-packages\\sklearn\\_loss\\loss.py:205\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mloss(\n\u001b[0;32m    197\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[0;32m    198\u001b[0m         raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    202\u001b[0m     )\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_out\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_gradient\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     y_true,\n\u001b[0;32m    208\u001b[0m     raw_prediction,\n\u001b[0;32m    209\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    210\u001b[0m     loss_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    211\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    212\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    213\u001b[0m ):\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m        Element-wise gradients.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_embed = OneVsRestClassifier(LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "model_embed.fit(X_embed_train, y_train_embed)\n",
    "y_pred_embed = model_embed.predict(X_embed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 AUC Scores for: Word Embedding + MLP\n",
      "  toxic          : 0.915\n",
      "  severe_toxic   : 0.959\n",
      "  obscene        : 0.935\n",
      "  threat         : 0.938\n",
      "  insult         : 0.939\n",
      "  identity_hate  : 0.922\n",
      "\n",
      "Macro AUC: 0.935\n",
      "Micro AUC: 0.950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'toxic': 0.9146341362472059,\n",
       "  'severe_toxic': 0.9594673423736554,\n",
       "  'obscene': 0.9350311142432376,\n",
       "  'threat': 0.937704404571023,\n",
       "  'insult': 0.9391071683215415,\n",
       "  'identity_hate': 0.9218693359510719},\n",
       " 0.9346355836179558,\n",
       " 0.9502655512378966)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming model_embed_mlp is trained\n",
    "y_scores_embed = model_mlp_embed.predict_proba(X_embed_val)\n",
    "y_val_embed_array = y_val_embed.values # Convert to NumPy array if it's a DataFrame\n",
    "\n",
    "evaluate_auc(y_val_embed_array, y_scores_embed, \"Word Embedding + MLP\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9bed26b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[282], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate KNN models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y_scores_knn_tfidf \u001b[38;5;241m=\u001b[39m model_knn_tfidf\u001b[38;5;241m.\u001b[39mpredict_proba(X_tfidf_val)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mevaluate_auc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_scores_knn_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTF-IDF + KNN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_scores_knn_embed \u001b[38;5;241m=\u001b[39m model_knn_embed\u001b[38;5;241m.\u001b[39mpredict_proba(X_embed_val) \n",
      "Cell \u001b[1;32mIn[279], line 18\u001b[0m, in \u001b[0;36mevaluate_auc\u001b[1;34m(y_true, y_scores, model_name, labels)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m         auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_true[:, i], \u001b[43my_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# If only one class present in y_true\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# Evaluate KNN models\n",
    "y_scores_knn_tfidf = model_knn_tfidf.predict_proba(X_tfidf_val)\n",
    "evaluate_auc(y_val_array, y_scores_knn_tfidf, \"TF-IDF + KNN\", labels)\n",
    "y_scores_knn_embed = model_knn_embed.predict_proba(X_embed_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation helpers\n",
    "def bar_true_vs_pred(y_true: pd.DataFrame,\n",
    "                     y_pred: np.ndarray,\n",
    "                     labels: list,\n",
    "                     title_suffix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Side-by-side bar chart of true vs. predicted counts for each label.\n",
    "    Works for multilabel problems (y_true is a DataFrame of 0/1 columns).\n",
    "    \"\"\"\n",
    "    true_counts = y_true.values.sum(axis=0)\n",
    "    pred_counts = y_pred.sum(axis=0)\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(x - .2, true_counts,  width=.4, label=\"True\", color=\"steelblue\")\n",
    "    plt.bar(x + .2, pred_counts, width=.4, label=\"Pred\", color=\"tomato\")\n",
    "\n",
    "    plt.xticks(x, labels, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Samples\")\n",
    "    plt.title(f\"True vs. Predicted counts {title_suffix}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def per_label_confusion_matrices(y_true: pd.DataFrame,\n",
    "                                 y_pred: np.ndarray,\n",
    "                                 labels: list,\n",
    "                                 cmap=\"YlOrRd\"):\n",
    "    \"\"\"\n",
    "    For each label produce a 2×2 confusion-matrix heat-map.\n",
    "    \"\"\"\n",
    "    n = len(labels)\n",
    "    ncols = 3\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols,\n",
    "                             figsize=(4*ncols, 4*nrows),\n",
    "                             squeeze=False)\n",
    "    for idx, lab in enumerate(labels):\n",
    "        r, c = divmod(idx, ncols)\n",
    "        cm = confusion_matrix(y_true[lab], y_pred[:, idx])\n",
    "        sns.heatmap(cm,\n",
    "                    annot=True, fmt=\"d\",\n",
    "                    cbar=False, cmap=cmap,\n",
    "                    ax=axes[r, c])\n",
    "        axes[r, c].set_title(lab)\n",
    "        axes[r, c].set_xlabel(\"Predicted\")\n",
    "        axes[r, c].set_ylabel(\"True\")\n",
    "    # turn off empty plots\n",
    "    for j in range(idx+1, nrows*ncols):\n",
    "        r, c = divmod(j, ncols)\n",
    "        axes[r, c].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def per_label_roc_curves(y_true: pd.DataFrame,\n",
    "                         y_prob: np.ndarray,\n",
    "                         labels: list):\n",
    "    \"\"\"\n",
    "    Draw ROC curve for every label (works if you have probability scores).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true[lab], y_prob[:, i])\n",
    "        auc  = roc_auc_score(y_true[lab], y_prob[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{lab} (AUC={auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\", color=\"grey\")\n",
    "    plt.xlabel(\"False-positive rate\")\n",
    "    plt.ylabel(\"True-positive rate\")\n",
    "    plt.title(\"ROC curves (per label)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def classification_table(y_true: pd.DataFrame,\n",
    "                         y_pred: np.ndarray,\n",
    "                         labels: list):\n",
    "    \"\"\"\n",
    "    Nicely formatted per-label precision / recall / F1.\n",
    "    Suppresses KeyError if a summary row is missing.\n",
    "    \"\"\"\n",
    "    report = classification_report(y_true.values,\n",
    "                                   y_pred,\n",
    "                                   target_names=labels,\n",
    "                                   output_dict=True,\n",
    "                                   zero_division=0)\n",
    "    df = (pd.DataFrame(report).T\n",
    "            .drop([\"accuracy\", \"macro avg\", \"weighted avg\",\n",
    "                   \"micro avg\", \"samples avg\"],\n",
    "                  errors=\"ignore\"))            # <-- key change\n",
    "    display(df.style.format(\"{:.3f}\")\n",
    "                  .background_gradient(cmap=\"Blues\"))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb96b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1c0f1_row0_col0 {\n",
       "  background-color: #3888c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row0_col1 {\n",
       "  background-color: #084990;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row0_col2 {\n",
       "  background-color: #1b69af;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row0_col3, #T_1c0f1_row2_col0, #T_1c0f1_row2_col2, #T_1c0f1_row4_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row1_col0 {\n",
       "  background-color: #e7f0fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row1_col1 {\n",
       "  background-color: #c9ddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row1_col2 {\n",
       "  background-color: #ddeaf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row1_col3 {\n",
       "  background-color: #f1f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row2_col1 {\n",
       "  background-color: #08326e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row2_col3 {\n",
       "  background-color: #549fcd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row3_col0, #T_1c0f1_row3_col1, #T_1c0f1_row3_col2, #T_1c0f1_row3_col3 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row4_col0 {\n",
       "  background-color: #3383be;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row4_col2 {\n",
       "  background-color: #115ca5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row4_col3 {\n",
       "  background-color: #79b5d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row5_col0 {\n",
       "  background-color: #b0d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row5_col1 {\n",
       "  background-color: #2c7cba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1c0f1_row5_col2 {\n",
       "  background-color: #7cb7da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1c0f1_row5_col3 {\n",
       "  background-color: #e3eef8;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1c0f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1c0f1_level0_col0\" class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th id=\"T_1c0f1_level0_col1\" class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th id=\"T_1c0f1_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_1c0f1_level0_col3\" class=\"col_heading level0 col3\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1c0f1_level0_row0\" class=\"row_heading level0 row0\" >toxic</th>\n",
       "      <td id=\"T_1c0f1_row0_col0\" class=\"data row0 col0\" >0.569</td>\n",
       "      <td id=\"T_1c0f1_row0_col1\" class=\"data row0 col1\" >0.637</td>\n",
       "      <td id=\"T_1c0f1_row0_col2\" class=\"data row0 col2\" >0.601</td>\n",
       "      <td id=\"T_1c0f1_row0_col3\" class=\"data row0 col3\" >91.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c0f1_level0_row1\" class=\"row_heading level0 row1\" >severe_toxic</th>\n",
       "      <td id=\"T_1c0f1_row1_col0\" class=\"data row1 col0\" >0.071</td>\n",
       "      <td id=\"T_1c0f1_row1_col1\" class=\"data row1 col1\" >0.167</td>\n",
       "      <td id=\"T_1c0f1_row1_col2\" class=\"data row1 col2\" >0.100</td>\n",
       "      <td id=\"T_1c0f1_row1_col3\" class=\"data row1 col3\" >6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c0f1_level0_row2\" class=\"row_heading level0 row2\" >obscene</th>\n",
       "      <td id=\"T_1c0f1_row2_col0\" class=\"data row2 col0\" >0.860</td>\n",
       "      <td id=\"T_1c0f1_row2_col1\" class=\"data row2 col1\" >0.698</td>\n",
       "      <td id=\"T_1c0f1_row2_col2\" class=\"data row2 col2\" >0.771</td>\n",
       "      <td id=\"T_1c0f1_row2_col3\" class=\"data row2 col3\" >53.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c0f1_level0_row3\" class=\"row_heading level0 row3\" >threat</th>\n",
       "      <td id=\"T_1c0f1_row3_col0\" class=\"data row3 col0\" >0.000</td>\n",
       "      <td id=\"T_1c0f1_row3_col1\" class=\"data row3 col1\" >0.000</td>\n",
       "      <td id=\"T_1c0f1_row3_col2\" class=\"data row3 col2\" >0.000</td>\n",
       "      <td id=\"T_1c0f1_row3_col3\" class=\"data row3 col3\" >3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c0f1_level0_row4\" class=\"row_heading level0 row4\" >insult</th>\n",
       "      <td id=\"T_1c0f1_row4_col0\" class=\"data row4 col0\" >0.585</td>\n",
       "      <td id=\"T_1c0f1_row4_col1\" class=\"data row4 col1\" >0.705</td>\n",
       "      <td id=\"T_1c0f1_row4_col2\" class=\"data row4 col2\" >0.639</td>\n",
       "      <td id=\"T_1c0f1_row4_col3\" class=\"data row4 col3\" >44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c0f1_level0_row5\" class=\"row_heading level0 row5\" >identity_hate</th>\n",
       "      <td id=\"T_1c0f1_row5_col0\" class=\"data row5 col0\" >0.273</td>\n",
       "      <td id=\"T_1c0f1_row5_col1\" class=\"data row5 col1\" >0.500</td>\n",
       "      <td id=\"T_1c0f1_row5_col2\" class=\"data row5 col2\" >0.353</td>\n",
       "      <td id=\"T_1c0f1_row5_col3\" class=\"data row5 col3\" >12.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x187c4a5bfe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.601036</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precision    recall  f1-score  support\n",
       "toxic           0.568627  0.637363  0.601036     91.0\n",
       "severe_toxic    0.071429  0.166667  0.100000      6.0\n",
       "obscene         0.860465  0.698113  0.770833     53.0\n",
       "threat          0.000000  0.000000  0.000000      3.0\n",
       "insult          0.584906  0.704545  0.639175     44.0\n",
       "identity_hate   0.272727  0.500000  0.352941     12.0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test_lg  : DataFrame of ground truth  (shape = [n_samples, 6])\n",
    "# y_pred_lg  : binary numpy array from model.predict(...)\n",
    "# y_prob_lg  : probability/decision scores (optional, for ROC curves)\n",
    "\n",
    "bar_true_vs_pred(y_test_lg, y_pred_lg, labels,\n",
    "                 title_suffix=\"(Logistic Regression)\")\n",
    "\n",
    "per_label_confusion_matrices(y_test_lg, y_pred_lg, labels)\n",
    "\n",
    "classification_table(y_test_lg, y_pred_lg, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1101e22",
   "metadata": {},
   "source": [
    "### Helper to train & collect metrics (reuse your visual-helpers later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd58bd8",
   "metadata": {},
   "source": [
    "###  Train all 3 models on word-TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0849a5",
   "metadata": {},
   "source": [
    "### Train the same 3 models on char-TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b993b",
   "metadata": {},
   "source": [
    "### Compare everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98678a2",
   "metadata": {},
   "source": [
    "### Visualise the best combo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8a1e8",
   "metadata": {},
   "source": [
    "### Kaggle submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
